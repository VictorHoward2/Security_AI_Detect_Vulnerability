{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31194, 3)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_full = pd.read_csv('./CVEFixes-kaggle.csv')\n",
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8632, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c = df_full[df_full['language'] == 'c']\n",
    "df_c.shape\n",
    "# lấy ngẫu nhiên 800 trường hợp trong dataset\n",
    "data = df_c\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "# Tải tokenizer và model codeBERT\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "model = RobertaModel.from_pretrained(\"microsoft/codebert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CodeVulnerabilityClassifier(nn.Module):\n",
    "    def __init__(self, codebert_model):\n",
    "        super(CodeVulnerabilityClassifier, self).__init__()\n",
    "        self.codebert = codebert_model\n",
    "        for param in self.codebert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.fc1 = nn.Linear(768, 512)  # 768 is the hidden state size of codeBERT\n",
    "        self.bn1 = nn.BatchNorm1d(512)  # Add Batch Normalization layer after the first linear layer\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.codebert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs[1]  # Get the hidden state of the [CLS] token\n",
    "        out1 = F.relu(self.bn1(self.fc1(pooled_output)))  # Apply ReLU activation to the output of BatchNorm of the first linear layer\n",
    "        out2 = F.relu(self.fc2(out1))  # Apply ReLU activation to the second linear layer output\n",
    "        logits = self.fc3(out2)  # Pass the output through the third linear layer\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia tập dữ liệu thành tập train và tập test (giả sử data là dataframe chứa 'code' và 'safety' fields)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tiền xử lý dữ liệu và chuyển đổi thành dạng tensor sử dụng tokenizer\n",
    "train_texts = train_data['code'].tolist()\n",
    "train_labels = [0 if label == 'safe' else 1 for label in train_data['safety']]\n",
    "\n",
    "test_texts = test_data['code'].tolist()\n",
    "test_labels = [0 if label == 'safe' else 1 for label in test_data['safety']]\n",
    "\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], torch.tensor(train_labels))\n",
    "test_dataset = torch.utils.data.TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], torch.tensor(test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a221be4c777c4538b45df42fc6cbf34d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9633, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6421, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6714, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6692, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7802, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7619, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6988, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7407, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8323, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7870, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6848, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7676, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6931, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6945, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7376, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6681, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6839, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6891, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7693, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6340, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8054, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6731, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6709, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6820, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6619, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7066, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6695, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6562, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6528, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6859, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6667, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6997, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7411, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6941, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7225, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6510, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6947, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6865, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8425, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6811, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6932, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6659, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6800, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6524, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6945, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6887, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6689, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7352, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7478, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7147, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6949, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7335, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6913, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6796, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6725, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6681, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6981, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6688, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6965, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6674, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6918, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7486, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6983, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6433, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6867, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7426, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6957, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7473, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6717, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6940, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6980, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6909, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6817, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6565, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6591, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6805, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6893, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6847, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6764, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6910, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6865, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7030, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6929, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6723, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6967, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6859, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6966, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7282, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6912, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7060, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6635, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6935, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6752, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6922, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6767, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6741, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6740, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6299, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6795, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6899, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6685, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6889, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6861, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6810, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6822, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6711, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6764, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6876, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6847, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6887, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7083, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6556, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6485, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7052, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6769, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6881, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6906, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6966, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6653, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6890, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6818, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6768, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6624, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6506, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6970, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7064, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6828, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6958, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6740, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6694, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6997, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6907, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6884, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6698, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6951, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6703, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6970, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6727, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6837, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6694, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7755, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6957, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6697, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6956, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6794, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6893, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6956, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6876, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6776, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6906, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6988, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6918, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6866, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7082, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7006, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6877, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6834, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6897, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6721, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7000, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6848, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6753, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6922, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6734, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6809, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6923, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6968, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6743, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6900, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6931, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6958, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6961, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6733, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6722, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6939, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6949, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6970, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6682, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6727, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6496, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6945, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6722, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6908, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7047, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6762, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6868, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6902, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6942, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6723, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6900, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6980, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6865, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6951, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6694, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6748, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6961, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6511, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6729, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6736, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6556, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6710, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6907, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7040, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6683, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6367, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6608, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6682, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7311, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6711, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7101, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6888, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6722, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6781, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6773, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6680, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6975, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6858, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6905, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6994, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6902, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6706, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6918, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6486, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6994, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6978, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6763, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6755, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6938, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6553, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6724, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6729, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6874, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6917, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6944, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6958, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6741, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6912, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6997, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6701, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6959, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6932, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6705, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6717, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6961, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6898, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6924, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6842, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6907, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6928, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6724, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6714, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6955, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6924, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6943, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6946, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6513, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6512, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6702, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6727, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6927, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6736, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6929, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6680, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6963, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6938, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6935, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6882, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6959, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6935, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6906, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6733, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6963, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6859, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6923, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6912, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6750, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6948, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6897, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6718, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6670, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6706, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6572, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6793, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6920, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6726, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6688, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6933, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6746, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6918, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6954, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6346, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6994, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6923, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6924, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6937, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6943, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6704, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6919, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6700, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6899, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6894, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6919, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6919, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6945, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6912, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6671, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6713, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6713, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6955, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6929, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6902, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7819, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6925, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6898, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6963, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6782, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6739, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6941, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6888, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6978, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6752, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6946, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6896, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6769, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6735, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6788, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6760, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6594, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6930, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6767, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6968, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6971, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6862, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6958, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6947, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6762, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6891, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6950, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6598, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6758, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6801, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6741, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6935, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6964, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6983, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6912, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6809, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6900, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6678, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6948, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6929, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8150, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6922, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6782, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6932, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6916, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6702, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6860, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6699, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6533, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6796, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6952, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6876, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6917, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6901, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6771, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6653, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6878, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6752, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6948, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6958, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6862, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6707, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6745, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6988, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6939, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6564, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6744, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6512, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6805, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6932, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6931, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6710, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7022, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6741, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7000, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6966, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6338, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6836, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6880, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6540, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6688, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6951, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6929, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6711, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6949, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6921, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6980, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6683, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6912, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6818, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6914, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6925, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6908, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6570, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6771, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6756, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6969, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6705, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6908, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6950, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6695, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6763, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6743, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7212, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6671, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6680, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6965, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7023, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6925, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6975, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6730, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6964, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6726, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6743, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6751, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6896, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6663, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6869, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6859, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6909, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6976, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6907, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6862, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6679, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6860, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6465, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6613, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6515, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6762, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7336, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7256, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6793, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6915, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6913, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6893, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6722, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6718, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6868, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6938, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6736, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6722, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6944, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6900, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6916, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6939, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6971, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6913, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6915, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6908, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6927, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6948, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6760, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6934, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6867, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6925, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6925, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6930, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6699, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6961, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6687, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6956, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6929, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6958, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6712, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6714, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6954, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6914, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6959, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6857, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6700, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6916, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6897, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6730, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6926, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6892, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6941, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6686, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6981, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7392, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6917, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6936, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6445, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6709, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6539, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6928, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6938, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6701, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6657, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6566, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6896, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6983, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6913, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6838, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6718, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6712, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6947, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6936, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6844, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6755, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6893, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6706, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6980, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6986, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6746, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6748, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6725, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6899, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6670, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6893, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6985, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6898, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6923, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6734, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6972, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6920, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6730, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6895, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6787, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6849, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6915, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6715, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6943, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6975, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6793, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6961, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6947, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6970, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6560, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6957, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6909, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6743, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6950, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6726, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6953, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6745, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6894, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6499, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6716, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6947, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6690, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6694, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6698, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6946, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6924, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6928, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6759, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6754, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6954, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6902, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6893, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6696, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6545, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6713, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6535, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6928, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6479, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6951, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6874, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6685, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6934, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6714, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6738, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7059, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6930, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6926, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6727, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6925, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6946, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8387, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6956, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6731, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6507, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6942, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6927, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6716, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6952, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6923, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6917, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6933, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6923, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6927, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6928, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6793, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6939, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6931, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6918, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6741, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6653, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6745, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6771, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6740, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6725, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6549, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6720, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6922, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6909, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6940, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6923, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6864, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6921, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6885, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6920, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6889, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Huấn luyện mô hình\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "classifier = CodeVulnerabilityClassifier(model)\n",
    "classifier.to(device)\n",
    "\n",
    "optimizer = optim.AdamW(classifier.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "for epoch in tqdm(range(3), total=3):\n",
    "    for input_ids, attention_mask, labels in train_loader:\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = classifier(input_ids, attention_mask)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.519976838448176\n"
     ]
    }
   ],
   "source": [
    "# Đánh giá mô hình trên tập test\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for input_ids, attention_mask, labels in test_loader:\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "        \n",
    "        logits = classifier(input_ids, attention_mask)\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy on test set: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
